# -*- coding: utf-8 -*-
"""week1 & 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17wpfHTKAXkbIu01wzgJJSPg3hgSl5O3u
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import Binarizer

# Load the new data
df = pd.read_excel('/content/ecommerce_price_predictor_combined_with_sales_discounted.xlsx')
print("Data Preview:")
print(df.head())

"""# Data cleaning and Pre-processing

"""

# Check for missing values
print("\nMissing values:")
print(df.isnull().sum())

df[df.isnull().any(axis=1)]

df.shape

df.columns

df.dropna()

df.duplicated().sum()

df.count()

numerical_df = df._get_numeric_data()
numerical_df

# UnivariateAnalysis: Distribution of Discounts
plt.figure(figsize=(8, 5))
sns.histplot(df["Discount (%)"], bins=30, kde=True, color="blue")
plt.title("Distribution of Discounts")
plt.xlabel("Discount (%)")
plt.ylabel("Frequency")
plt.show()

# Univariate: Count of Products by Category
plt.figure(figsize=(8, 5))
sns.countplot(x=df["Category"], order=df["Category"].value_counts().index, palette="viridis")
plt.title("Count of Products by Category")
plt.xticks(rotation=45)
plt.show()

# Bivariate: Relationship Between Discount & Sales
plt.figure(figsize=(8, 5))
sns.scatterplot(x=df["Discount (%)"], y=df["Discounted Price (USD)"], alpha=0.5)
plt.title("Impact of Discounts on Sales Price")
plt.xlabel("Discount (%)")
plt.ylabel("Discounted Price (USD)")
plt.show()

# @title Ratings
numerical_df['Rating'].plot(kind='hist', bins=20, title='Rating')
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title Ratings vs Reviews=]
numerical_df.plot(kind='scatter', x='Rating', y='Reviews Count', s=20, alpha=.8)
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title Discount (%) vs Original_Price

from matplotlib import pyplot as plt
numerical_df.plot(kind='scatter', x='Discount (%)', y='Price (USD)', s=20, alpha=.8)
plt.gca().spines[['top', 'right',]].set_visible(False)

# Calculate the minimum value for numeric columns only
numerical_df = df.select_dtypes(include=np.number)          #df.max()// df.min() didnt work
df_min = numerical_df.min()

# Display the minimum values
print(df_min)

# Calculate the minimum value for numeric columns only
numerical_df = df.select_dtypes(include=np.number)          #df.max()// df.min() didnt work
df_max = numerical_df.max()

# Display the minimum values
print(df_max)

# Correlation heatmap
# Correlation heatmap
plt.figure(figsize=(8,6))
# Select only numerical features for correlation analysis
numerical_df = df.select_dtypes(include=np.number)
sns.heatmap(numerical_df.corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Feature Correlation Heatmap")
plt.show()

X_demand = df[['Price (USD)', 'Discounted Price (USD)']]  # Adjust based on dataset columns
y_demand = df['Demand Index']
X_train, X_test, y_train, y_test = train_test_split(X_demand, y_demand, test_size=0.2, random_state=42)

model_demand = LinearRegression()
model_demand.fit(X_train,y_train)

#Demand Analysis (Total Sales by Product(category))

# Calculate total sales per product
total_sales = df.groupby("Category")["Discounted Price (USD)"].sum().reset_index()
total_sales.rename(columns={"Discounted Price (USD)": "Total_Sales"}, inplace=True)

# Display top products by sales
print(total_sales.sort_values(by="Total_Sales", ascending=False).head(10))

#Total Sales per Product

total_sales = df.groupby("Product Name")["Discounted Price (USD)"].sum().reset_index()
total_sales.rename(columns={"Discounted Price (USD)": "Total_Sales"}, inplace=True)

# Print top 15 products by total sales
print("Total Sales per Product:")
print(total_sales.sort_values(by="Total_Sales", ascending=False).head(15))

avg_prices = df.groupby('Category').agg({
    'Price (USD)': 'mean',
    'Competitor Price (USD)': 'mean'
}).reset_index()

avg_prices_melted = avg_prices.melt(id_vars='Category',
                                    value_vars=['Price (USD)', 'Competitor Price (USD)'],
                                    var_name='Price Type', value_name='Average Price')

plt.figure(figsize=(10, 6))
sns.barplot(x='Category', y='Average Price', hue='Price Type', data=avg_prices_melted)
plt.title('Comparison of Average Prices Between Platform and Competitors')
plt.xticks(rotation=45)
plt.ylabel('Average Price (USD)')
plt.show()

# Group by product and calculate total sales
total_sales = df.groupby('Product Name')['Sales (Units Sold)'].sum().reset_index()
total_sales.rename(columns={'Sales (Units Sold)': 'Total Sales'}, inplace=True)

# Plot total sales distribution
plt.figure(figsize=(8, 5))
sns.histplot(total_sales['Total Sales'], bins=30, kde=True, color='blue')
plt.title('Total Sales Distribution by Product')
plt.xlabel('Total Sales (Units Sold)')
plt.ylabel('Frequency')
plt.show()

features = df[['Price (USD)', 'Discount (%)', 'Competitor Price (USD)', 'Sales (Units Sold)']]
target = df['Discounted Price (USD)']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)

# Initialize and train the linear regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# Calculate and print model accuracy
errors = abs(y_pred - y_test)
accuracy = 100 - (100 * (errors.sum() / y_test.sum()))

print(f"Linear Regression Model Accuracy: {accuracy:.2f}%")

from sklearn.preprocessing import LabelEncoder

# Initialize LabelEncoder
label_encoder = LabelEncoder()

# Categorical columns to encode
categorical_columns = ['Category', 'Brand', 'Stock Availability', 'Return Policy', 'Competitor Name', 'Competitor Stock Availability']

# Apply LabelEncoder to each column
for col in categorical_columns:
    if col in df.columns:
        df[col] = label_encoder.fit_transform(df[col])

# Show the transformed dataframe
print(df.head())

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# Selecting relevant features for demand prediction
features = ['Price (USD)', 'Discount (%)', 'Rating', 'Reviews Count',
            'Shipping Time (days)', 'Competitor Price Difference (%)',
            'Profit Margin (%)', 'Customer Satisfaction (%)',
            'Supply Chain Efficiency (%)']
target = 'Sales (Units Sold)'

# Preparing the feature matrix (X) and target vector (y)
X = df[features]
y = df[target]

# Splitting data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initializing and training the Random Forest Regressor
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Predictions
y_pred = rf_model.predict(X_test)

# Model evaluation
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

(mae, rmse, r2)

# Get feature importances from the Random Forest model
importances = rf_model.feature_importances_
feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': importances})
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

# Plot Feature Importance
plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette='viridis')
plt.title('Feature Importance for Demand Prediction (Sales)')
plt.show()

"""# **walmart-API**"""

import http.client

conn = http.client.HTTPSConnection("walmart-data.p.rapidapi.com")

headers = {
    'x-rapidapi-key': "2ab6aa1c26msh99cbdca2111eb1ap13df56jsn89409570906f",
    'x-rapidapi-host': "walmart-data.p.rapidapi.com"
}

conn.request("GET", "/walmart-serp.php?url=https%3A%2F%2Fwww.walmart.com%2Fsearch%3Fq%3Dsamsung%2Bgalaxy", headers=headers)

res = conn.getresponse()
data = res.read()

print(data.decode("utf-8"))

import pandas as pd
import numpy as np
from sklearn.preprocessing import Binarizer

# Load the Excel file from local path
df = pd.read_excel('/content/ecommerce_price_predictor_combined_with_sales_discounted.xlsx')

# Display column names to understand the structure
print("Column Names:\n", df.columns)

# Select numerical columns only
numerical_columns = df.select_dtypes(include=['number']).columns
X = df[numerical_columns].values  # Extract numerical features

# Apply Binarizer (threshold = 0.0 by default)
binarizer = Binarizer(threshold=0.0).fit(X)
binaryX = binarizer.transform(X)

# Convert the transformed array back to a DataFrame for better readability
binary_df = pd.DataFrame(binaryX, columns=numerical_columns)

# Display first 5 rows
binary_df.head()