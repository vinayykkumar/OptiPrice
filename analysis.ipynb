{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mg9s8mgp-_o"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "data = pd.read_csv('/content/merged_data.csv')  # Replace with your file path\n",
        "\n",
        "# Step 2: Preprocess the data\n",
        "data['Date of Travel'] = pd.to_datetime(data['Date of Travel'])\n",
        "data['Travel_Year'] = data['Date of Travel'].dt.year\n",
        "data['Travel_Month'] = data['Date of Travel'].dt.month\n",
        "data['Travel_Day'] = data['Date of Travel'].dt.day\n",
        "data = data.drop(columns=['Date of Travel'])\n",
        "\n",
        "# Encode categorical columns\n",
        "label_encoders = {}\n",
        "categorical_cols = ['Company', 'City', 'Payment_Mode', 'Gender', 'Month']\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Prepare features (X) and target (y)\n",
        "exclude_cols = ['Profit', 'Price Charged', 'Cost of Trip', 'Income (USD/Month)', 'Age']\n",
        "X = data.drop(columns=exclude_cols)\n",
        "y = data['Profit']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features (important for Ridge and Lasso)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqMbI2jgqz9P",
        "outputId": "293e1b11-377e-4c51-91cd-0424cd9ab831"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Ridge Regression ===\n",
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
            "\n",
            "Best Hyperparameters for Ridge:\n",
            "{'alpha': 10.0}\n",
            "Best MSE (negative): -18072.44\n",
            "\n",
            "Ridge Regression Performance on Test Data:\n",
            "Mean Squared Error: 18190.98\n",
            "R² Score: 0.30\n",
            "Root Mean Squared Error (per trip): $134.87\n",
            "Accuracy (within ±$50 tolerance): 37.54%\n",
            "\n",
            "Ridge Regression Feature Coefficients:\n",
            "                  Feature  Coefficient\n",
            "2  Distance Travelled(KM)    73.976684\n",
            "0                 Company    40.668219\n",
            "8            Travel_Month   -14.058876\n",
            "1                    City     9.905493\n",
            "6                    Year    -4.916546\n",
            "7             Travel_Year    -4.916546\n",
            "5                   Month     2.608825\n",
            "4                  Gender     2.392127\n",
            "9              Travel_Day    -1.159043\n",
            "3            Payment_Mode     0.241310\n",
            "\n",
            "Average Trips per Month: 9983\n",
            "Enter the year for profit prediction (e.g., 2025): 2025\n",
            "Enter the month for profit prediction (1-12): 2\n",
            "\n",
            "Ridge Predicted Total Company Profit for 2/2025: $1,131,179.83\n",
            "Estimated Range: $-215,266.57–$2,477,626.24\n",
            "(Note: Range based on RMSE ±$134.87 per trip across 9983 trips)\n",
            "\n",
            "Ridge Profit Breakdown by Company for 2/2025:\n",
            "Pink Cab: $65,064.39 (Range: $-12,381.93–$142,510.72)\n",
            "Yellow Cab: $1,066,115.44 (Range: $-202,884.64–$2,335,115.52)\n",
            "Total (Pink Cab + Yellow Cab): $1,131,179.83\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Ridge Regression\n",
        "print(\"\\n=== Ridge Regression ===\")\n",
        "\n",
        "# Define Ridge model and hyperparameter grid\n",
        "ridge = Ridge(random_state=42)\n",
        "ridge_param_grid = {'alpha': [0.01, 0.1, 1.0, 10.0, 100.0]}\n",
        "\n",
        "# Perform GridSearchCV\n",
        "ridge_grid_search = GridSearchCV(\n",
        "    estimator=ridge,\n",
        "    param_grid=ridge_param_grid,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=3,\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "ridge_grid_search.fit(X_train_scaled, y_train)\n",
        "ridge_best_params = ridge_grid_search.best_params_\n",
        "print(\"\\nBest Hyperparameters for Ridge:\")\n",
        "print(ridge_best_params)\n",
        "print(f\"Best MSE (negative): {ridge_grid_search.best_score_:.2f}\")\n",
        "\n",
        "# Train Ridge model with best parameters\n",
        "ridge_model = Ridge(**ridge_best_params, random_state=42)\n",
        "ridge_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate on test set\n",
        "ridge_y_pred = ridge_model.predict(X_test_scaled)\n",
        "ridge_mse = mean_squared_error(y_test, ridge_y_pred)\n",
        "ridge_r2 = r2_score(y_test, ridge_y_pred)\n",
        "ridge_rmse = np.sqrt(ridge_mse)\n",
        "\n",
        "# Calculate tolerance-based accuracy\n",
        "tolerance = 50  # Consider predictions within $50 of the true profit as \"accurate\"\n",
        "ridge_absolute_errors = np.abs(ridge_y_pred - y_test)\n",
        "ridge_accuracy_within_tolerance = np.mean(ridge_absolute_errors <= tolerance) * 100\n",
        "\n",
        "print(\"\\nRidge Regression Performance on Test Data:\")\n",
        "print(f\"Mean Squared Error: {ridge_mse:.2f}\")\n",
        "print(f\"R² Score: {ridge_r2:.2f}\")\n",
        "print(f\"Root Mean Squared Error (per trip): ${ridge_rmse:.2f}\")\n",
        "print(f\"Accuracy (within ±$50 tolerance): {ridge_accuracy_within_tolerance:.2f}%\")\n",
        "\n",
        "# Feature coefficients (importance)\n",
        "ridge_coefficients = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Coefficient': ridge_model.coef_\n",
        "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
        "print(\"\\nRidge Regression Feature Coefficients:\")\n",
        "print(ridge_coefficients)\n",
        "\n",
        "# Step 4: Predict future profits with Ridge\n",
        "def generate_future_data(base_data, year, month, num_trips, scaler):\n",
        "    historical_month_data = base_data[base_data['Travel_Month'] == month].copy()\n",
        "    if historical_month_data.empty:\n",
        "        historical_month_data = base_data.copy()\n",
        "\n",
        "    future_data = historical_month_data.sample(n=num_trips, replace=True, random_state=42).copy()\n",
        "    future_data['Travel_Year'] = year\n",
        "    future_data['Travel_Month'] = month\n",
        "    future_data['Travel_Day'] = np.random.randint(1, 31, size=num_trips)\n",
        "    years_diff = year - 2018\n",
        "    future_data['Price Charged'] *= (1 + 0.02) ** years_diff  # 2% inflation\n",
        "    future_data['Cost of Trip'] *= (1 + 0.02) ** years_diff   # 2% inflation\n",
        "    future_X = future_data.drop(columns=['Profit', 'Price Charged', 'Cost of Trip', 'Income (USD/Month)', 'Age'])\n",
        "    return future_X, future_data, scaler.transform(future_X)\n",
        "\n",
        "avg_trips_per_month = len(data) // (data['Travel_Year'].nunique() * 12)\n",
        "print(f\"\\nAverage Trips per Month: {avg_trips_per_month}\")\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_year = int(input(\"Enter the year for profit prediction (e.g., 2025): \"))\n",
        "        user_month = int(input(\"Enter the month for profit prediction (1-12): \"))\n",
        "        if 1 <= user_month <= 12 and user_year >= 2019:\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid input. Month must be 1-12, and year must be 2019 or later.\")\n",
        "    except ValueError:\n",
        "        print(\"Please enter valid numeric values.\")\n",
        "\n",
        "# Generate future data and predict profits\n",
        "future_X, future_data, future_X_scaled = generate_future_data(data, user_year, user_month, avg_trips_per_month, scaler)\n",
        "ridge_future_pred_profits = ridge_model.predict(future_X_scaled)\n",
        "\n",
        "# Total profit with confidence interval\n",
        "ridge_total_future_profit = ridge_future_pred_profits.sum()\n",
        "ridge_total_error = ridge_rmse * avg_trips_per_month\n",
        "print(f\"\\nRidge Predicted Total Company Profit for {user_month}/{user_year}: ${ridge_total_future_profit:,.2f}\")\n",
        "print(f\"Estimated Range: ${ridge_total_future_profit - ridge_total_error:,.2f}–${ridge_total_future_profit + ridge_total_error:,.2f}\")\n",
        "print(f\"(Note: Range based on RMSE ±${ridge_rmse:.2f} per trip across {avg_trips_per_month} trips)\")\n",
        "\n",
        "# Breakdown by company\n",
        "future_data['Predicted_Profit'] = ridge_future_pred_profits\n",
        "future_data['Company'] = label_encoders['Company'].inverse_transform(future_data['Company'])\n",
        "ridge_profit_by_company = future_data.groupby('Company')['Predicted_Profit'].sum()\n",
        "ridge_pink_cab_profit = ridge_profit_by_company.get('Pink Cab', 0)\n",
        "ridge_yellow_cab_profit = ridge_profit_by_company.get('Yellow Cab', 0)\n",
        "ridge_pink_error = ridge_total_error * (ridge_pink_cab_profit / ridge_total_future_profit) if ridge_total_future_profit != 0 else 0\n",
        "ridge_yellow_error = ridge_total_error * (ridge_yellow_cab_profit / ridge_total_future_profit) if ridge_total_future_profit != 0 else 0\n",
        "\n",
        "print(f\"\\nRidge Profit Breakdown by Company for {user_month}/{user_year}:\")\n",
        "print(f\"Pink Cab: ${ridge_pink_cab_profit:,.2f} (Range: ${ridge_pink_cab_profit - ridge_pink_error:,.2f}–${ridge_pink_cab_profit + ridge_pink_error:,.2f})\")\n",
        "print(f\"Yellow Cab: ${ridge_yellow_cab_profit:,.2f} (Range: ${ridge_yellow_cab_profit - ridge_yellow_error:,.2f}–${ridge_yellow_cab_profit + ridge_yellow_error:,.2f})\")\n",
        "print(f\"Total (Pink Cab + Yellow Cab): ${(ridge_pink_cab_profit + ridge_yellow_cab_profit):,.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptWZOXoXsRQ3",
        "outputId": "a7d6dbfa-546b-4696-e281-84ff4e68fb4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Lasso Regression ===\n",
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
            "\n",
            "Best Hyperparameters for Lasso:\n",
            "{'alpha': 0.01}\n",
            "Best MSE (negative): -18072.44\n",
            "\n",
            "Lasso Regression Performance on Test Data:\n",
            "Mean Squared Error: 18191.03\n",
            "R² Score: 0.30\n",
            "Root Mean Squared Error (per trip): $134.87\n",
            "Accuracy (within ±$50 tolerance): 37.53%\n",
            "\n",
            "Lasso Regression Feature Coefficients:\n",
            "                  Feature   Coefficient\n",
            "2  Distance Travelled(KM)  7.396927e+01\n",
            "0                 Company  4.066006e+01\n",
            "8            Travel_Month -1.404699e+01\n",
            "1                    City  9.895806e+00\n",
            "6                    Year -9.822952e+00\n",
            "5                   Month  2.595749e+00\n",
            "4                  Gender  2.382457e+00\n",
            "9              Travel_Day -1.149170e+00\n",
            "3            Payment_Mode  2.313607e-01\n",
            "7             Travel_Year -2.470550e-15\n",
            "\n",
            "Lasso Predicted Total Company Profit for 2/2025: $1,621,046.43\n",
            "Estimated Range: $274,597.87–$2,967,495.00\n",
            "(Note: Range based on RMSE ±$134.87 per trip across 9983 trips)\n",
            "\n",
            "Lasso Profit Breakdown by Company for 2/2025:\n",
            "Pink Cab: $155,326.08 (Range: $26,311.53–$284,340.63)\n",
            "Yellow Cab: $1,465,720.35 (Range: $248,286.34–$2,683,154.37)\n",
            "Total (Pink Cab + Yellow Cab): $1,621,046.43\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Lasso Regression\n",
        "print(\"\\n=== Lasso Regression ===\")\n",
        "\n",
        "# Define Lasso model and hyperparameter grid\n",
        "lasso = Lasso(random_state=42, max_iter=10000)\n",
        "lasso_param_grid = {'alpha': [0.01, 0.1, 1.0, 10.0, 100.0]}\n",
        "\n",
        "# Perform GridSearchCV\n",
        "lasso_grid_search = GridSearchCV(\n",
        "    estimator=lasso,\n",
        "    param_grid=lasso_param_grid,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=3,\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lasso_grid_search.fit(X_train_scaled, y_train)\n",
        "lasso_best_params = lasso_grid_search.best_params_\n",
        "print(\"\\nBest Hyperparameters for Lasso:\")\n",
        "print(lasso_best_params)\n",
        "print(f\"Best MSE (negative): {lasso_grid_search.best_score_:.2f}\")\n",
        "\n",
        "# Train Lasso model with best parameters\n",
        "lasso_model = Lasso(**lasso_best_params, random_state=42, max_iter=10000)\n",
        "lasso_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate on test set\n",
        "lasso_y_pred = lasso_model.predict(X_test_scaled)\n",
        "lasso_mse = mean_squared_error(y_test, lasso_y_pred)\n",
        "lasso_r2 = r2_score(y_test, lasso_y_pred)\n",
        "lasso_rmse = np.sqrt(lasso_mse)\n",
        "\n",
        "# Calculate tolerance-based accuracy\n",
        "lasso_absolute_errors = np.abs(lasso_y_pred - y_test)\n",
        "lasso_accuracy_within_tolerance = np.mean(lasso_absolute_errors <= tolerance) * 100\n",
        "\n",
        "print(\"\\nLasso Regression Performance on Test Data:\")\n",
        "print(f\"Mean Squared Error: {lasso_mse:.2f}\")\n",
        "print(f\"R² Score: {lasso_r2:.2f}\")\n",
        "print(f\"Root Mean Squared Error (per trip): ${lasso_rmse:.2f}\")\n",
        "print(f\"Accuracy (within ±$50 tolerance): {lasso_accuracy_within_tolerance:.2f}%\")\n",
        "\n",
        "# Feature coefficients (importance)\n",
        "lasso_coefficients = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Coefficient': lasso_model.coef_\n",
        "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
        "print(\"\\nLasso Regression Feature Coefficients:\")\n",
        "print(lasso_coefficients)\n",
        "\n",
        "# Step 6: Predict future profits with Lasso\n",
        "future_X, future_data, future_X_scaled = generate_future_data(data, user_year, user_month, avg_trips_per_month, scaler)\n",
        "lasso_future_pred_profits = lasso_model.predict(future_X_scaled)\n",
        "\n",
        "# Total profit with confidence interval\n",
        "lasso_total_future_profit = lasso_future_pred_profits.sum()\n",
        "lasso_total_error = lasso_rmse * avg_trips_per_month\n",
        "print(f\"\\nLasso Predicted Total Company Profit for {user_month}/{user_year}: ${lasso_total_future_profit:,.2f}\")\n",
        "print(f\"Estimated Range: ${lasso_total_future_profit - lasso_total_error:,.2f}–${lasso_total_future_profit + lasso_total_error:,.2f}\")\n",
        "print(f\"(Note: Range based on RMSE ±${lasso_rmse:.2f} per trip across {avg_trips_per_month} trips)\")\n",
        "\n",
        "# Breakdown by company\n",
        "future_data['Predicted_Profit'] = lasso_future_pred_profits\n",
        "future_data['Company'] = label_encoders['Company'].inverse_transform(future_data['Company'])\n",
        "lasso_profit_by_company = future_data.groupby('Company')['Predicted_Profit'].sum()\n",
        "lasso_pink_cab_profit = lasso_profit_by_company.get('Pink Cab', 0)\n",
        "lasso_yellow_cab_profit = lasso_profit_by_company.get('Yellow Cab', 0)\n",
        "lasso_pink_error = lasso_total_error * (lasso_pink_cab_profit / lasso_total_future_profit) if lasso_total_future_profit != 0 else 0\n",
        "lasso_yellow_error = lasso_total_error * (lasso_yellow_cab_profit / lasso_total_future_profit) if lasso_total_future_profit != 0 else 0\n",
        "\n",
        "print(f\"\\nLasso Profit Breakdown by Company for {user_month}/{user_year}:\")\n",
        "print(f\"Pink Cab: ${lasso_pink_cab_profit:,.2f} (Range: ${lasso_pink_cab_profit - lasso_pink_error:,.2f}–${lasso_pink_cab_profit + lasso_pink_error:,.2f})\")\n",
        "print(f\"Yellow Cab: ${lasso_yellow_cab_profit:,.2f} (Range: ${lasso_yellow_cab_profit - lasso_yellow_error:,.2f}–${lasso_yellow_cab_profit + lasso_yellow_error:,.2f})\")\n",
        "print(f\"Total (Pink Cab + Yellow Cab): ${(lasso_pink_cab_profit + lasso_yellow_cab_profit):,.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke34f7yUsdv9",
        "outputId": "2f199c04-8f1a-4e6f-c948-ed05d47655a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Comparison of Ridge and Lasso Regression ===\n",
            "   Model           MSE  R² Score        RMSE  Accuracy (within ±$50)  \\\n",
            "0  Ridge  18190.976033  0.297028  134.873926               37.538085   \n",
            "1  Lasso  18191.034386  0.297025  134.874143               37.532520   \n",
            "\n",
            "   Total Profit (Predicted)  Profit Range (Lower)  Profit Range (Upper)  \n",
            "0              1.131180e+06        -215266.572743          2.477626e+06  \n",
            "1              1.621046e+06         274597.865776          2.967495e+06  \n"
          ]
        }
      ],
      "source": [
        "# Step 7: Compare Ridge and Lasso\n",
        "print(\"\\n=== Comparison of Ridge and Lasso Regression ===\")\n",
        "comparison = pd.DataFrame({\n",
        "    'Model': ['Ridge', 'Lasso'],\n",
        "    'MSE': [ridge_mse, lasso_mse],\n",
        "    'R² Score': [ridge_r2, lasso_r2],\n",
        "    'RMSE': [ridge_rmse, lasso_rmse],\n",
        "    'Accuracy (within ±$50)': [ridge_accuracy_within_tolerance, lasso_accuracy_within_tolerance],\n",
        "    'Total Profit (Predicted)': [ridge_total_future_profit, lasso_total_future_profit],\n",
        "    'Profit Range (Lower)': [ridge_total_future_profit - ridge_total_error, lasso_total_future_profit - lasso_total_error],\n",
        "    'Profit Range (Upper)': [ridge_total_future_profit + ridge_total_error, lasso_total_future_profit + lasso_total_error]\n",
        "})\n",
        "print(comparison)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrPkAZs7sh4E",
        "outputId": "04fa23f3-dc50-4c65-e23f-30391a3a5e97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Dataset Exploration ===\n",
            "Number of rows: 359392\n",
            "Number of columns: 13\n",
            "\n",
            "Column names and data types:\n",
            "Date of Travel             object\n",
            "Company                    object\n",
            "City                       object\n",
            "Distance Travelled(KM)    float64\n",
            "Price Charged             float64\n",
            "Cost of Trip              float64\n",
            "Payment_Mode               object\n",
            "Gender                     object\n",
            "Age                         int64\n",
            "Income (USD/Month)          int64\n",
            "Profit                    float64\n",
            "Month                      object\n",
            "Year                        int64\n",
            "dtype: object\n",
            "\n",
            "Missing values per column:\n",
            "Date of Travel            0\n",
            "Company                   0\n",
            "City                      0\n",
            "Distance Travelled(KM)    0\n",
            "Price Charged             0\n",
            "Cost of Trip              0\n",
            "Payment_Mode              0\n",
            "Gender                    0\n",
            "Age                       0\n",
            "Income (USD/Month)        0\n",
            "Profit                    0\n",
            "Month                     0\n",
            "Year                      0\n",
            "dtype: int64\n",
            "\n",
            "Basic statistics for numerical columns:\n",
            "       Distance Travelled(KM)  Price Charged   Cost of Trip            Age  \\\n",
            "count           359392.000000  359392.000000  359392.000000  359392.000000   \n",
            "mean                22.567254     423.443311     286.190113      35.336705   \n",
            "std                 12.233526     274.378911     157.993661      12.594234   \n",
            "min                  1.900000      15.600000      19.000000      18.000000   \n",
            "25%                 12.000000     206.437500     151.200000      25.000000   \n",
            "50%                 22.440000     386.360000     282.480000      33.000000   \n",
            "75%                 32.960000     583.660000     413.683200      42.000000   \n",
            "max                 48.000000    2048.030000     691.200000      65.000000   \n",
            "\n",
            "       Income (USD/Month)         Profit           Year  \n",
            "count       359392.000000  359392.000000  359392.000000  \n",
            "mean         15048.822937     137.253198    2017.045199  \n",
            "std           7969.409482     160.311840       0.800239  \n",
            "min           2000.000000    -220.060000    2016.000000  \n",
            "25%           8424.000000      28.012000    2016.000000  \n",
            "50%          14685.000000      81.962000    2017.000000  \n",
            "75%          21035.000000     190.030000    2018.000000  \n",
            "max          35000.000000    1463.966000    2018.000000  \n",
            "\n",
            "Unique values in categorical columns:\n",
            "Company: ['Pink Cab' 'Yellow Cab']\n",
            "City: ['ATLANTA GA' 'AUSTIN TX' 'BOSTON MA' 'CHICAGO IL' 'DALLAS TX' 'DENVER CO'\n",
            " 'LOS ANGELES CA' 'MIAMI FL' 'NASHVILLE TN' 'NEW YORK NY' 'ORANGE COUNTY'\n",
            " 'PHOENIX AZ' 'PITTSBURGH PA' 'SACRAMENTO CA' 'SAN DIEGO CA' 'SEATTLE WA'\n",
            " 'SILICON VALLEY' 'TUCSON AZ' 'WASHINGTON DC']\n",
            "Payment_Mode: ['Card' 'Cash']\n",
            "Gender: ['Male' 'Female']\n",
            "Month: ['January' 'February' 'March' 'April' 'May' 'June' 'July' 'August'\n",
            " 'September' 'October' 'November' 'December']\n",
            "\n",
            "Sample of the dataset (first 5 rows):\n",
            "  Date of Travel   Company        City  Distance Travelled(KM)  Price Charged  \\\n",
            "0     2016-01-08  Pink Cab  ATLANTA GA                   30.45         370.95   \n",
            "1     2016-01-06  Pink Cab  ATLANTA GA                   28.62         358.52   \n",
            "2     2016-01-02  Pink Cab  ATLANTA GA                    9.04         125.20   \n",
            "3     2016-01-07  Pink Cab  ATLANTA GA                   33.17         377.40   \n",
            "4     2016-01-03  Pink Cab  ATLANTA GA                    8.73         114.62   \n",
            "\n",
            "   Cost of Trip Payment_Mode Gender  Age  Income (USD/Month)  Profit    Month  \\\n",
            "0       313.635         Card   Male   28               10813  57.315  January   \n",
            "1       334.854         Card   Male   27                9237  23.666  January   \n",
            "2        97.632         Cash   Male   53               11242  27.568  January   \n",
            "3       351.602         Cash   Male   23               23327  25.798  January   \n",
            "4        97.776         Card   Male   33                8536  16.844  January   \n",
            "\n",
            "   Year  \n",
            "0  2016  \n",
            "1  2016  \n",
            "2  2016  \n",
            "3  2016  \n",
            "4  2016  \n",
            "\n",
            "=== Prepared Data for LightGBM ===\n",
            "Training set shape: (287513, 10)\n",
            "Test set shape: (71879, 10)\n",
            "Target variable (y) range: min=-220.06, max=1463.97, mean=137.25\n",
            "\n",
            "Features prepared for LightGBM (X):\n",
            "['Company', 'City', 'Distance Travelled(KM)', 'Payment_Mode', 'Gender', 'Month', 'Year', 'Travel_Year', 'Travel_Month', 'Travel_Day']\n",
            "\n",
            "Sample of prepared features (first 5 rows of X_train):\n",
            "        Company  City  Distance Travelled(KM)  Payment_Mode  Gender  Month  \\\n",
            "333706        1     3                   27.75             0       1      9   \n",
            "7591          1     3                   34.20             0       1      3   \n",
            "297131        0    11                    4.76             0       0      1   \n",
            "33355         1     9                   24.57             0       0      6   \n",
            "172007        0     3                   16.80             0       0      1   \n",
            "\n",
            "        Year  Travel_Year  Travel_Month  Travel_Day  \n",
            "333706  2018         2018            11          16  \n",
            "7591    2016         2016             2          16  \n",
            "297131  2018         2018             8          24  \n",
            "33355   2016         2016             6           4  \n",
            "172007  2017         2017             8          20  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "data = pd.read_csv('/content/merged_data.csv')  # Replace with your file path\n",
        "\n",
        "# Step 2: Explore the dataset\n",
        "print(\"=== Dataset Exploration ===\")\n",
        "\n",
        "# Number of rows and columns\n",
        "print(f\"Number of rows: {data.shape[0]}\")\n",
        "print(f\"Number of columns: {data.shape[1]}\")\n",
        "\n",
        "# Column names and data types\n",
        "print(\"\\nColumn names and data types:\")\n",
        "print(data.dtypes)\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Basic statistics for numerical columns\n",
        "print(\"\\nBasic statistics for numerical columns:\")\n",
        "print(data.describe())\n",
        "\n",
        "# Unique values in categorical columns\n",
        "categorical_cols = ['Company', 'City', 'Payment_Mode', 'Gender', 'Month']\n",
        "print(\"\\nUnique values in categorical columns:\")\n",
        "for col in categorical_cols:\n",
        "    if col in data.columns:\n",
        "        print(f\"{col}: {data[col].unique()}\")\n",
        "\n",
        "# Sample of the first few rows\n",
        "print(\"\\nSample of the dataset (first 5 rows):\")\n",
        "print(data.head())\n",
        "\n",
        "# Step 3: Preprocess the data\n",
        "# Convert 'Date of Travel' to datetime and extract components\n",
        "if 'Date of Travel' in data.columns:\n",
        "    data['Date of Travel'] = pd.to_datetime(data['Date of Travel'])\n",
        "    data['Travel_Year'] = data['Date of Travel'].dt.year\n",
        "    data['Travel_Month'] = data['Date of Travel'].dt.month\n",
        "    data['Travel_Day'] = data['Date of Travel'].dt.day\n",
        "    data = data.drop(columns=['Date of Travel'])\n",
        "else:\n",
        "    print(\"Warning: 'Date of Travel' not found. Ensure 'Travel_Year', 'Travel_Month', 'Travel_Day' are present.\")\n",
        "    required_date_cols = ['Travel_Year', 'Travel_Month', 'Travel_Day']\n",
        "    if not all(col in data.columns for col in required_date_cols):\n",
        "        raise KeyError(\"Dataset must contain either 'Date of Travel' or preprocessed 'Travel_Year', 'Travel_Month', 'Travel_Day' columns\")\n",
        "\n",
        "# Encode categorical columns\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    if col in data.columns:\n",
        "        le = LabelEncoder()\n",
        "        data[col] = le.fit_transform(data[col])\n",
        "        label_encoders[col] = le\n",
        "    else:\n",
        "        print(f\"Warning: '{col}' not found in dataset, skipping encoding\")\n",
        "\n",
        "# Step 4: Prepare features (X) and target (y) for LightGBM\n",
        "exclude_cols = ['Profit', 'Price Charged', 'Cost of Trip', 'Income (USD/Month)', 'Age']\n",
        "X = data.drop(columns=exclude_cols)\n",
        "y = data['Profit']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5: Convert to LightGBM Dataset (before training)\n",
        "train_data = lgb.Dataset(X_train, label=y_train)\n",
        "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
        "\n",
        "# Step 6: Print prepared data summary\n",
        "print(\"\\n=== Prepared Data for LightGBM ===\")\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "print(f\"Target variable (y) range: min={y.min():.2f}, max={y.max():.2f}, mean={y.mean():.2f}\")\n",
        "print(\"\\nFeatures prepared for LightGBM (X):\")\n",
        "print(X.columns.tolist())\n",
        "print(\"\\nSample of prepared features (first 5 rows of X_train):\")\n",
        "print(X_train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuebiOIhvjEl",
        "outputId": "c175aca3-1f89-4450-e872-8e9e7e29135b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training LightGBM Model...\n",
            "[10]\tvalid_0's l2: 9947\n",
            "[20]\tvalid_0's l2: 6222.64\n",
            "[30]\tvalid_0's l2: 5466.64\n",
            "[40]\tvalid_0's l2: 5224.18\n",
            "[50]\tvalid_0's l2: 5025.66\n",
            "[60]\tvalid_0's l2: 4920.94\n",
            "[70]\tvalid_0's l2: 4849.04\n",
            "[80]\tvalid_0's l2: 4788.95\n",
            "[90]\tvalid_0's l2: 4759.51\n",
            "[100]\tvalid_0's l2: 4702.81\n",
            "\n",
            "LightGBM Performance on Test Data:\n",
            "Mean Squared Error: 4702.81\n",
            "R² Score: 0.82\n",
            "Root Mean Squared Error (per trip): $68.58\n",
            "Accuracy (within ±$50 tolerance): 67.28%\n",
            "\n",
            "LightGBM Feature Importance:\n",
            "                  Feature    Importance\n",
            "1                    City  1.025571e+10\n",
            "2  Distance Travelled(KM)  9.639423e+09\n",
            "0                 Company  2.982890e+09\n",
            "5                   Month  1.286400e+09\n",
            "7            Travel_Month  6.944023e+08\n",
            "6             Travel_Year  3.338823e+08\n",
            "8              Travel_Day  2.670672e+08\n",
            "3            Payment_Mode  1.002593e+06\n",
            "4                  Gender  8.595656e+05\n",
            "\n",
            "Average Trips per Month: 9983\n",
            "Enter the year for profit prediction (e.g., 2025): 2025\n",
            "Enter the month for profit prediction (1-12): 2\n",
            "\n",
            "Predicted Total Company Profit for 2/2025: $1,555,674.19\n",
            "Estimated Range: $871,069.36–$2,240,279.02\n",
            "(Note: Range based on RMSE ±$68.58 per trip across 9983 trips)\n",
            "\n",
            "Profit Breakdown by Company for 2/2025:\n",
            "Pink Cab: $113,066.81 (Range: $63,309.55–$162,824.06)\n",
            "Yellow Cab: $1,442,607.39 (Range: $807,759.82–$2,077,454.96)\n",
            "Total (Pink Cab + Yellow Cab): $1,555,674.19\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Step 1: Load and preprocess the dataset (using your output as reference)\n",
        "data = pd.read_csv('/content/merged_data.csv')  # Replace with your file path\n",
        "\n",
        "# Convert 'Date of Travel' to datetime and extract components\n",
        "data['Date of Travel'] = pd.to_datetime(data['Date of Travel'])\n",
        "data['Travel_Year'] = data['Date of Travel'].dt.year\n",
        "data['Travel_Month'] = data['Date of Travel'].dt.month\n",
        "data['Travel_Day'] = data['Date of Travel'].dt.day\n",
        "data = data.drop(columns=['Date of Travel'])\n",
        "\n",
        "# Encode categorical columns\n",
        "categorical_cols = ['Company', 'City', 'Payment_Mode', 'Gender', 'Month']\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Prepare features (X) and target (y)\n",
        "exclude_cols = ['Profit', 'Price Charged', 'Cost of Trip', 'Income (USD/Month)', 'Age', 'Year']  # Drop 'Year' to avoid multicollinearity\n",
        "X = data.drop(columns=exclude_cols)\n",
        "y = data['Profit']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Convert to LightGBM Dataset with categorical features\n",
        "train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_cols, free_raw_data=False)\n",
        "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data, categorical_feature=categorical_cols, free_raw_data=False)\n",
        "\n",
        "# Step 3: Define LightGBM parameters\n",
        "params = {\n",
        "    'objective': 'regression',  # Regression task\n",
        "    'metric': 'mse',           # Mean Squared Error\n",
        "    'boosting_type': 'gbdt',   # Traditional Gradient Boosting Decision Tree\n",
        "    'num_leaves': 31,          # Number of leaves in one tree\n",
        "    'learning_rate': 0.1,      # Step size shrinkage\n",
        "    'feature_fraction': 0.9,   # Fraction of features to consider per tree\n",
        "    'bagging_fraction': 0.8,   # Fraction of data to use for bagging\n",
        "    'bagging_freq': 5,         # Frequency of bagging\n",
        "    'verbose': -1,             # No verbose output during training\n",
        "    'n_jobs': -1              # Use all available cores\n",
        "}\n",
        "\n",
        "# Step 4: Train the model\n",
        "num_round = 100  # Number of boosting iterations\n",
        "print(\"\\nTraining LightGBM Model...\")\n",
        "gbm = lgb.train(params, train_data, num_boost_round=num_round, valid_sets=[test_data], callbacks=[lgb.log_evaluation(period=10)])\n",
        "\n",
        "# Step 5: Evaluate the model\n",
        "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "# Calculate tolerance-based accuracy\n",
        "tolerance = 50  # Predictions within $50 of true profit\n",
        "absolute_errors = np.abs(y_pred - y_test)\n",
        "accuracy_within_tolerance = np.mean(absolute_errors <= tolerance) * 100\n",
        "\n",
        "print(\"\\nLightGBM Performance on Test Data:\")\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "print(f\"R² Score: {r2:.2f}\")\n",
        "print(f\"Root Mean Squared Error (per trip): ${rmse:.2f}\")\n",
        "print(f\"Accuracy (within ±$50 tolerance): {accuracy_within_tolerance:.2f}%\")\n",
        "\n",
        "# Step 6: Feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': gbm.feature_importance(importance_type='gain')\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "print(\"\\nLightGBM Feature Importance:\")\n",
        "print(feature_importance)\n",
        "\n",
        "# Step 7: Function to generate synthetic data with 2% inflation\n",
        "def generate_future_data(base_data, year, month, num_trips, scaler=None):\n",
        "    historical_month_data = base_data[base_data['Travel_Month'] == month].copy()\n",
        "    if historical_month_data.empty:\n",
        "        historical_month_data = base_data.copy()\n",
        "\n",
        "    future_data = historical_month_data.sample(n=num_trips, replace=True, random_state=42).copy()\n",
        "    future_data['Travel_Year'] = year\n",
        "    future_data['Travel_Month'] = month\n",
        "    future_data['Travel_Day'] = np.random.randint(1, 31, size=num_trips)\n",
        "    years_diff = year - 2018\n",
        "    future_data['Price Charged'] *= (1 + 0.02) ** years_diff  # 2% inflation\n",
        "    future_data['Cost of Trip'] *= (1 + 0.02) ** years_diff   # 2% inflation\n",
        "    future_X = future_data.drop(columns=exclude_cols)\n",
        "    return future_X, future_data\n",
        "\n",
        "avg_trips_per_month = len(data) // (data['Travel_Year'].nunique() * 12)\n",
        "print(f\"\\nAverage Trips per Month: {avg_trips_per_month}\")\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_year = int(input(\"Enter the year for profit prediction (e.g., 2025): \"))\n",
        "        user_month = int(input(\"Enter the month for profit prediction (1-12): \"))\n",
        "        if 1 <= user_month <= 12 and user_year >= 2019:\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid input. Month must be 1-12, and year must be 2019 or later.\")\n",
        "    except ValueError:\n",
        "        print(\"Please enter valid numeric values.\")\n",
        "\n",
        "# Generate future data and predict profits\n",
        "future_X, future_data = generate_future_data(data, user_year, user_month, avg_trips_per_month)\n",
        "future_pred_profits = gbm.predict(future_X)\n",
        "\n",
        "# Total profit with confidence interval\n",
        "total_future_profit = future_pred_profits.sum()\n",
        "total_error = rmse * avg_trips_per_month\n",
        "print(f\"\\nPredicted Total Company Profit for {user_month}/{user_year}: ${total_future_profit:,.2f}\")\n",
        "print(f\"Estimated Range: ${total_future_profit - total_error:,.2f}–${total_future_profit + total_error:,.2f}\")\n",
        "print(f\"(Note: Range based on RMSE ±${rmse:.2f} per trip across {avg_trips_per_month} trips)\")\n",
        "\n",
        "# Breakdown by company\n",
        "future_data['Predicted_Profit'] = future_pred_profits\n",
        "future_data['Company'] = label_encoders['Company'].inverse_transform(future_data['Company'])\n",
        "profit_by_company = future_data.groupby('Company')['Predicted_Profit'].sum()\n",
        "pink_cab_profit = profit_by_company.get('Pink Cab', 0)\n",
        "yellow_cab_profit = profit_by_company.get('Yellow Cab', 0)\n",
        "pink_error = total_error * (pink_cab_profit / total_future_profit) if total_future_profit != 0 else 0\n",
        "yellow_error = total_error * (yellow_cab_profit / total_future_profit) if total_future_profit != 0 else 0\n",
        "\n",
        "print(f\"\\nProfit Breakdown by Company for {user_month}/{user_year}:\")\n",
        "print(f\"Pink Cab: ${pink_cab_profit:,.2f} (Range: ${pink_cab_profit - pink_error:,.2f}–${pink_cab_profit + pink_error:,.2f})\")\n",
        "print(f\"Yellow Cab: ${yellow_cab_profit:,.2f} (Range: ${yellow_cab_profit - yellow_error:,.2f}–${yellow_cab_profit + yellow_error:,.2f})\")\n",
        "print(f\"Total (Pink Cab + Yellow Cab): ${(pink_cab_profit + yellow_cab_profit):,.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-3bzvfGv0E_",
        "outputId": "9354e206-1e19-447b-dad4-fa6a624f79bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training LightGBM Model with Early Stopping...\n",
            "Training until validation scores don't improve for 20 rounds\n",
            "[10]\tvalid_0's l2: 16209.8\n",
            "[20]\tvalid_0's l2: 10958.1\n",
            "[30]\tvalid_0's l2: 8269.72\n",
            "[40]\tvalid_0's l2: 6978.08\n",
            "[50]\tvalid_0's l2: 6169.17\n",
            "[60]\tvalid_0's l2: 5682.16\n",
            "[70]\tvalid_0's l2: 5427.69\n",
            "[80]\tvalid_0's l2: 5263.17\n",
            "[90]\tvalid_0's l2: 5153.47\n",
            "[100]\tvalid_0's l2: 5078.43\n",
            "[110]\tvalid_0's l2: 5007.06\n",
            "[120]\tvalid_0's l2: 4945.51\n",
            "[130]\tvalid_0's l2: 4907.55\n",
            "[140]\tvalid_0's l2: 4872.67\n",
            "[150]\tvalid_0's l2: 4834.95\n",
            "[160]\tvalid_0's l2: 4792.48\n",
            "[170]\tvalid_0's l2: 4771.43\n",
            "[180]\tvalid_0's l2: 4752.26\n",
            "[190]\tvalid_0's l2: 4722.35\n",
            "[200]\tvalid_0's l2: 4710.77\n",
            "[210]\tvalid_0's l2: 4684.69\n",
            "[220]\tvalid_0's l2: 4671.17\n",
            "[230]\tvalid_0's l2: 4649.75\n",
            "[240]\tvalid_0's l2: 4634.77\n",
            "[250]\tvalid_0's l2: 4622.72\n",
            "[260]\tvalid_0's l2: 4606.47\n",
            "[270]\tvalid_0's l2: 4598.23\n",
            "[280]\tvalid_0's l2: 4588.48\n",
            "[290]\tvalid_0's l2: 4575.11\n",
            "[300]\tvalid_0's l2: 4558.89\n",
            "[310]\tvalid_0's l2: 4550.17\n",
            "[320]\tvalid_0's l2: 4540.75\n",
            "[330]\tvalid_0's l2: 4530.99\n",
            "[340]\tvalid_0's l2: 4517.15\n",
            "[350]\tvalid_0's l2: 4511.85\n",
            "[360]\tvalid_0's l2: 4501.49\n",
            "[370]\tvalid_0's l2: 4494.4\n",
            "[380]\tvalid_0's l2: 4478.44\n",
            "[390]\tvalid_0's l2: 4471.35\n",
            "[400]\tvalid_0's l2: 4468.09\n",
            "[410]\tvalid_0's l2: 4456.58\n",
            "[420]\tvalid_0's l2: 4453.15\n",
            "[430]\tvalid_0's l2: 4443.99\n",
            "[440]\tvalid_0's l2: 4439.08\n",
            "[450]\tvalid_0's l2: 4432.39\n",
            "[460]\tvalid_0's l2: 4421.01\n",
            "[470]\tvalid_0's l2: 4414.03\n",
            "[480]\tvalid_0's l2: 4410.01\n",
            "[490]\tvalid_0's l2: 4399.61\n",
            "[500]\tvalid_0's l2: 4396.19\n",
            "[510]\tvalid_0's l2: 4386.64\n",
            "[520]\tvalid_0's l2: 4382.39\n",
            "[530]\tvalid_0's l2: 4378.46\n",
            "[540]\tvalid_0's l2: 4373.68\n",
            "[550]\tvalid_0's l2: 4371\n",
            "[560]\tvalid_0's l2: 4369.67\n",
            "[570]\tvalid_0's l2: 4365\n",
            "[580]\tvalid_0's l2: 4364.57\n",
            "[590]\tvalid_0's l2: 4362.08\n",
            "[600]\tvalid_0's l2: 4355.97\n",
            "[610]\tvalid_0's l2: 4348.55\n",
            "[620]\tvalid_0's l2: 4347.72\n",
            "[630]\tvalid_0's l2: 4343.61\n",
            "[640]\tvalid_0's l2: 4338.64\n",
            "[650]\tvalid_0's l2: 4335.99\n",
            "[660]\tvalid_0's l2: 4331.75\n",
            "[670]\tvalid_0's l2: 4328.84\n",
            "[680]\tvalid_0's l2: 4325.19\n",
            "[690]\tvalid_0's l2: 4320.65\n",
            "[700]\tvalid_0's l2: 4318.98\n",
            "[710]\tvalid_0's l2: 4314.43\n",
            "[720]\tvalid_0's l2: 4313.15\n",
            "[730]\tvalid_0's l2: 4304.8\n",
            "[740]\tvalid_0's l2: 4301.1\n",
            "[750]\tvalid_0's l2: 4296.54\n",
            "[760]\tvalid_0's l2: 4293.64\n",
            "[770]\tvalid_0's l2: 4287.73\n",
            "[780]\tvalid_0's l2: 4285.81\n",
            "[790]\tvalid_0's l2: 4286.05\n",
            "[800]\tvalid_0's l2: 4285.25\n",
            "[810]\tvalid_0's l2: 4285.3\n",
            "[820]\tvalid_0's l2: 4276.01\n",
            "[830]\tvalid_0's l2: 4273.01\n",
            "[840]\tvalid_0's l2: 4269.47\n",
            "[850]\tvalid_0's l2: 4267.69\n",
            "[860]\tvalid_0's l2: 4265.25\n",
            "[870]\tvalid_0's l2: 4263.19\n",
            "[880]\tvalid_0's l2: 4257.76\n",
            "[890]\tvalid_0's l2: 4256.94\n",
            "[900]\tvalid_0's l2: 4254.9\n",
            "[910]\tvalid_0's l2: 4249.28\n",
            "[920]\tvalid_0's l2: 4247.63\n",
            "[930]\tvalid_0's l2: 4246.49\n",
            "[940]\tvalid_0's l2: 4244.14\n",
            "[950]\tvalid_0's l2: 4241.23\n",
            "[960]\tvalid_0's l2: 4236.36\n",
            "[970]\tvalid_0's l2: 4233.82\n",
            "[980]\tvalid_0's l2: 4224\n",
            "[990]\tvalid_0's l2: 4219.67\n",
            "[1000]\tvalid_0's l2: 4218.14\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\tvalid_0's l2: 4218.14\n",
            "\n",
            "Optimized LightGBM Performance on Test Data:\n",
            "Mean Squared Error: 4218.14\n",
            "R² Score: 0.84\n",
            "Root Mean Squared Error (per trip): $64.95\n",
            "Accuracy (within ±$50 tolerance): 69.26%\n",
            "\n",
            "LightGBM Feature Importance:\n",
            "                  Feature    Importance\n",
            "1                    City  2.062758e+10\n",
            "2  Distance Travelled(KM)  1.919481e+10\n",
            "0                 Company  5.512124e+09\n",
            "6            Travel_Month  4.063542e+09\n",
            "7              Travel_Day  1.294918e+09\n",
            "5             Travel_Year  9.726511e+08\n",
            "4                  Gender  4.064328e+07\n",
            "3            Payment_Mode  3.685237e+07\n",
            "\n",
            "Average Trips per Month: 9983\n",
            "Enter the year for profit prediction (e.g., 2025): 2025\n",
            "Enter the month for profit prediction (1-12): 2\n",
            "\n",
            "Predicted Total Company Profit for 2/2025: $1,538,022.85\n",
            "Estimated Range: $889,655.00–$2,186,390.69\n",
            "(Note: Range based on RMSE ±$64.95 per trip across 9983 trips)\n",
            "\n",
            "Profit Breakdown by Company for 2/2025:\n",
            "Pink Cab: $111,864.04 (Range: $64,706.71–$159,021.36)\n",
            "Yellow Cab: $1,426,158.81 (Range: $824,948.29–$2,027,369.33)\n",
            "Total (Pink Cab + Yellow Cab): $1,538,022.85\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Step 1: Load and preprocess the dataset\n",
        "data = pd.read_csv('/content/merged_data.csv')\n",
        "\n",
        "# Convert 'Date of Travel' to datetime and extract components\n",
        "data['Date of Travel'] = pd.to_datetime(data['Date of Travel'])\n",
        "data['Travel_Year'] = data['Date of Travel'].dt.year\n",
        "data['Travel_Month'] = data['Date of Travel'].dt.month\n",
        "data['Travel_Day'] = data['Date of Travel'].dt.day\n",
        "data = data.drop(columns=['Date of Travel'])\n",
        "\n",
        "# Encode categorical columns\n",
        "categorical_cols = ['Company', 'City', 'Payment_Mode', 'Gender', 'Month']\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Prepare features (X) and target (y)\n",
        "exclude_cols = ['Profit', 'Price Charged', 'Cost of Trip', 'Income (USD/Month)', 'Age', 'Year', 'Month']  # Drop 'Year' and 'Month'\n",
        "X = data.drop(columns=exclude_cols)\n",
        "y = data['Profit']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Update categorical columns (exclude 'Month')\n",
        "categorical_cols = ['Company', 'City', 'Payment_Mode', 'Gender']\n",
        "\n",
        "# Step 2: Convert to LightGBM Dataset\n",
        "train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_cols, free_raw_data=False)\n",
        "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data, categorical_feature=categorical_cols, free_raw_data=False)\n",
        "\n",
        "# Step 3: Define LightGBM parameters with early stopping\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'mse',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 40,          # Increased from 31 to capture more complexity\n",
        "    'learning_rate': 0.05,     # Reduced from 0.1 for more stable learning\n",
        "    'feature_fraction': 0.8,   # Reduced to prevent overfitting\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'verbose': -1,\n",
        "    'n_jobs': -1,\n",
        "    'lambda_l1': 0.1,         # L1 regularization\n",
        "    'lambda_l2': 0.1          # L2 regularization\n",
        "}\n",
        "\n",
        "# Step 4: Train the model with early stopping\n",
        "num_round = 1000  # Higher max iterations, but early stopping will halt\n",
        "print(\"\\nTraining LightGBM Model with Early Stopping...\")\n",
        "gbm = lgb.train(\n",
        "    params,\n",
        "    train_data,\n",
        "    num_boost_round=num_round,\n",
        "    valid_sets=[test_data],\n",
        "    callbacks=[lgb.early_stopping(stopping_rounds=20), lgb.log_evaluation(period=10)]\n",
        ")\n",
        "\n",
        "# Step 5: Evaluate the model\n",
        "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "# Calculate tolerance-based accuracy\n",
        "tolerance = 50\n",
        "absolute_errors = np.abs(y_pred - y_test)\n",
        "accuracy_within_tolerance = np.mean(absolute_errors <= tolerance) * 100\n",
        "\n",
        "print(\"\\nOptimized LightGBM Performance on Test Data:\")\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "print(f\"R² Score: {r2:.2f}\")\n",
        "print(f\"Root Mean Squared Error (per trip): ${rmse:.2f}\")\n",
        "print(f\"Accuracy (within ±$50 tolerance): {accuracy_within_tolerance:.2f}%\")\n",
        "\n",
        "# Step 6: Feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': gbm.feature_importance(importance_type='gain')\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "print(\"\\nLightGBM Feature Importance:\")\n",
        "print(feature_importance)\n",
        "\n",
        "# Step 7: Function to generate synthetic data with 2% inflation\n",
        "def generate_future_data(base_data, year, month, num_trips):\n",
        "    historical_month_data = base_data[base_data['Travel_Month'] == month].copy()\n",
        "    if historical_month_data.empty:\n",
        "        historical_month_data = base_data.copy()\n",
        "\n",
        "    future_data = historical_month_data.sample(n=num_trips, replace=True, random_state=42).copy()\n",
        "    future_data['Travel_Year'] = year\n",
        "    future_data['Travel_Month'] = month\n",
        "    future_data['Travel_Day'] = np.random.randint(1, 31, size=num_trips)\n",
        "    years_diff = year - 2018\n",
        "    future_data['Price Charged'] *= (1 + 0.02) ** years_diff  # 2% inflation\n",
        "    future_data['Cost of Trip'] *= (1 + 0.02) ** years_diff   # 2% inflation\n",
        "    future_X = future_data.drop(columns=exclude_cols)\n",
        "    return future_X, future_data\n",
        "\n",
        "avg_trips_per_month = len(data) // (data['Travel_Year'].nunique() * 12)\n",
        "print(f\"\\nAverage Trips per Month: {avg_trips_per_month}\")\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_year = int(input(\"Enter the year for profit prediction (e.g., 2025): \"))\n",
        "        user_month = int(input(\"Enter the month for profit prediction (1-12): \"))\n",
        "        if 1 <= user_month <= 12 and user_year >= 2019:\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid input. Month must be 1-12, and year must be 2019 or later.\")\n",
        "    except ValueError:\n",
        "        print(\"Please enter valid numeric values.\")\n",
        "\n",
        "# Generate future data and predict profits\n",
        "future_X, future_data = generate_future_data(data, user_year, user_month, avg_trips_per_month)\n",
        "future_pred_profits = gbm.predict(future_X)\n",
        "\n",
        "# Total profit with confidence interval\n",
        "total_future_profit = future_pred_profits.sum()\n",
        "total_error = rmse * avg_trips_per_month\n",
        "print(f\"\\nPredicted Total Company Profit for {user_month}/{user_year}: ${total_future_profit:,.2f}\")\n",
        "print(f\"Estimated Range: ${total_future_profit - total_error:,.2f}–${total_future_profit + total_error:,.2f}\")\n",
        "print(f\"(Note: Range based on RMSE ±${rmse:.2f} per trip across {avg_trips_per_month} trips)\")\n",
        "\n",
        "# Breakdown by company\n",
        "future_data['Predicted_Profit'] = future_pred_profits\n",
        "future_data['Company'] = label_encoders['Company'].inverse_transform(future_data['Company'])\n",
        "profit_by_company = future_data.groupby('Company')['Predicted_Profit'].sum()\n",
        "pink_cab_profit = profit_by_company.get('Pink Cab', 0)\n",
        "yellow_cab_profit = profit_by_company.get('Yellow Cab', 0)\n",
        "pink_error = total_error * (pink_cab_profit / total_future_profit) if total_future_profit != 0 else 0\n",
        "yellow_error = total_error * (yellow_cab_profit / total_future_profit) if total_future_profit != 0 else 0\n",
        "\n",
        "print(f\"\\nProfit Breakdown by Company for {user_month}/{user_year}:\")\n",
        "print(f\"Pink Cab: ${pink_cab_profit:,.2f} (Range: ${pink_cab_profit - pink_error:,.2f}–${pink_cab_profit + pink_error:,.2f})\")\n",
        "print(f\"Yellow Cab: ${yellow_cab_profit:,.2f} (Range: ${yellow_cab_profit - yellow_error:,.2f}–${yellow_cab_profit + yellow_error:,.2f})\")\n",
        "print(f\"Total (Pink Cab + Yellow Cab): ${(pink_cab_profit + yellow_cab_profit):,.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9TiKfIUwvCF",
        "outputId": "410999b8-5eac-4a7b-e05e-87334646dc06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Performing Hyperparameter Tuning with GridSearchCV...\n",
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
            "\n",
            "Best Hyperparameters from Grid Search:\n",
            "{'learning_rate': 0.05, 'min_child_samples': 30, 'n_estimators': 1000, 'num_leaves': 50}\n",
            "Best MSE (negative): -19762.69\n",
            "\n",
            "Training Final LightGBM Model with Best Parameters...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 20 rounds\n",
            "[10]\tvalid_0's huber: 105.504\n",
            "[20]\tvalid_0's huber: 105.313\n",
            "[30]\tvalid_0's huber: 105.096\n",
            "[40]\tvalid_0's huber: 104.868\n",
            "[50]\tvalid_0's huber: 104.653\n",
            "[60]\tvalid_0's huber: 104.419\n",
            "[70]\tvalid_0's huber: 104.195\n",
            "[80]\tvalid_0's huber: 103.98\n",
            "[90]\tvalid_0's huber: 103.745\n",
            "[100]\tvalid_0's huber: 103.521\n",
            "[110]\tvalid_0's huber: 103.299\n",
            "[120]\tvalid_0's huber: 103.075\n",
            "[130]\tvalid_0's huber: 102.871\n",
            "[140]\tvalid_0's huber: 102.649\n",
            "[150]\tvalid_0's huber: 102.446\n",
            "[160]\tvalid_0's huber: 102.263\n",
            "[170]\tvalid_0's huber: 102.041\n",
            "[180]\tvalid_0's huber: 101.82\n",
            "[190]\tvalid_0's huber: 101.608\n",
            "[200]\tvalid_0's huber: 101.395\n",
            "[210]\tvalid_0's huber: 101.156\n",
            "[220]\tvalid_0's huber: 100.967\n",
            "[230]\tvalid_0's huber: 100.778\n",
            "[240]\tvalid_0's huber: 100.551\n",
            "[250]\tvalid_0's huber: 100.326\n",
            "[260]\tvalid_0's huber: 100.095\n",
            "[270]\tvalid_0's huber: 99.8773\n",
            "[280]\tvalid_0's huber: 99.6794\n",
            "[290]\tvalid_0's huber: 99.4461\n",
            "[300]\tvalid_0's huber: 99.22\n",
            "[310]\tvalid_0's huber: 99.0118\n",
            "[320]\tvalid_0's huber: 98.8026\n",
            "[330]\tvalid_0's huber: 98.598\n",
            "[340]\tvalid_0's huber: 98.3993\n",
            "[350]\tvalid_0's huber: 98.1839\n",
            "[360]\tvalid_0's huber: 97.9605\n",
            "[370]\tvalid_0's huber: 97.7367\n",
            "[380]\tvalid_0's huber: 97.5342\n",
            "[390]\tvalid_0's huber: 97.3233\n",
            "[400]\tvalid_0's huber: 97.1133\n",
            "[410]\tvalid_0's huber: 96.9133\n",
            "[420]\tvalid_0's huber: 96.7111\n",
            "[430]\tvalid_0's huber: 96.492\n",
            "[440]\tvalid_0's huber: 96.2909\n",
            "[450]\tvalid_0's huber: 96.0709\n",
            "[460]\tvalid_0's huber: 95.8726\n",
            "[470]\tvalid_0's huber: 95.6607\n",
            "[480]\tvalid_0's huber: 95.4514\n",
            "[490]\tvalid_0's huber: 95.2529\n",
            "[500]\tvalid_0's huber: 95.0266\n",
            "[510]\tvalid_0's huber: 94.822\n",
            "[520]\tvalid_0's huber: 94.6347\n",
            "[530]\tvalid_0's huber: 94.4365\n",
            "[540]\tvalid_0's huber: 94.2542\n",
            "[550]\tvalid_0's huber: 94.0564\n",
            "[560]\tvalid_0's huber: 93.8596\n",
            "[570]\tvalid_0's huber: 93.6653\n",
            "[580]\tvalid_0's huber: 93.4625\n",
            "[590]\tvalid_0's huber: 93.2703\n",
            "[600]\tvalid_0's huber: 93.0574\n",
            "[610]\tvalid_0's huber: 92.8589\n",
            "[620]\tvalid_0's huber: 92.6524\n",
            "[630]\tvalid_0's huber: 92.4516\n",
            "[640]\tvalid_0's huber: 92.2585\n",
            "[650]\tvalid_0's huber: 92.0769\n",
            "[660]\tvalid_0's huber: 91.8772\n",
            "[670]\tvalid_0's huber: 91.6735\n",
            "[680]\tvalid_0's huber: 91.4919\n",
            "[690]\tvalid_0's huber: 91.2919\n",
            "[700]\tvalid_0's huber: 91.0986\n",
            "[710]\tvalid_0's huber: 90.9111\n",
            "[720]\tvalid_0's huber: 90.7196\n",
            "[730]\tvalid_0's huber: 90.5406\n",
            "[740]\tvalid_0's huber: 90.3318\n",
            "[750]\tvalid_0's huber: 90.1425\n",
            "[760]\tvalid_0's huber: 89.9416\n",
            "[770]\tvalid_0's huber: 89.7281\n",
            "[780]\tvalid_0's huber: 89.5525\n",
            "[790]\tvalid_0's huber: 89.3578\n",
            "[800]\tvalid_0's huber: 89.1713\n",
            "[810]\tvalid_0's huber: 88.967\n",
            "[820]\tvalid_0's huber: 88.7704\n",
            "[830]\tvalid_0's huber: 88.5854\n",
            "[840]\tvalid_0's huber: 88.3849\n",
            "[850]\tvalid_0's huber: 88.2011\n",
            "[860]\tvalid_0's huber: 88\n",
            "[870]\tvalid_0's huber: 87.8189\n",
            "[880]\tvalid_0's huber: 87.6353\n",
            "[890]\tvalid_0's huber: 87.4685\n",
            "[900]\tvalid_0's huber: 87.2861\n",
            "[910]\tvalid_0's huber: 87.0932\n",
            "[920]\tvalid_0's huber: 86.9078\n",
            "[930]\tvalid_0's huber: 86.7361\n",
            "[940]\tvalid_0's huber: 86.5544\n",
            "[950]\tvalid_0's huber: 86.3648\n",
            "[960]\tvalid_0's huber: 86.1896\n",
            "[970]\tvalid_0's huber: 86.0164\n",
            "[980]\tvalid_0's huber: 85.8283\n",
            "[990]\tvalid_0's huber: 85.6398\n",
            "[1000]\tvalid_0's huber: 85.4556\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\tvalid_0's huber: 85.4556\n",
            "\n",
            "Final LightGBM Performance on Test Data:\n",
            "Mean Squared Error: 19877.53\n",
            "R² Score: 0.23\n",
            "Root Mean Squared Error (per trip): $140.99\n",
            "Accuracy (within ±$50 tolerance): 33.60%\n",
            "\n",
            "Final LightGBM Feature Importance:\n",
            "                  Feature    Importance\n",
            "1                    City  3.106526e+07\n",
            "8        Distance_Company  2.587677e+07\n",
            "2  Distance Travelled(KM)  1.448682e+07\n",
            "6            Travel_Month  3.218411e+06\n",
            "0                 Company  2.456237e+06\n",
            "5             Travel_Year  7.523672e+05\n",
            "7              Travel_Day  1.332568e+04\n",
            "4                  Gender  7.450073e+01\n",
            "3            Payment_Mode  0.000000e+00\n",
            "\n",
            "Average Trips per Month: 9983\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Step 1: Load and preprocess the dataset\n",
        "data = pd.read_csv('/content/merged_data.csv')\n",
        "\n",
        "# Convert 'Date of Travel' to datetime and extract components\n",
        "data['Date of Travel'] = pd.to_datetime(data['Date of Travel'])\n",
        "data['Travel_Year'] = data['Date of Travel'].dt.year\n",
        "data['Travel_Month'] = data['Date of Travel'].dt.month\n",
        "data['Travel_Day'] = data['Date of Travel'].dt.day\n",
        "data = data.drop(columns=['Date of Travel'])\n",
        "\n",
        "# Encode categorical columns\n",
        "categorical_cols = ['Company', 'City', 'Payment_Mode', 'Gender', 'Month']\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Feature engineering: Add interaction term\n",
        "data['Distance_Company'] = data['Distance Travelled(KM)'] * data['Company']\n",
        "\n",
        "# Prepare features (X) and target (y)\n",
        "exclude_cols = ['Profit', 'Price Charged', 'Cost of Trip', 'Income (USD/Month)', 'Age', 'Year', 'Month']\n",
        "X = data.drop(columns=exclude_cols)\n",
        "y = data['Profit']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Update categorical columns\n",
        "categorical_cols = ['Company', 'City', 'Payment_Mode', 'Gender']\n",
        "\n",
        "# Step 2: Hyperparameter tuning with GridSearchCV\n",
        "print(\"\\nPerforming Hyperparameter Tuning with GridSearchCV...\")\n",
        "gbm = lgb.LGBMRegressor(\n",
        "    objective='huber',  # Robust loss function\n",
        "    boosting_type='gbdt',\n",
        "    feature_fraction=0.8,\n",
        "    bagging_fraction=0.8,\n",
        "    bagging_freq=5,\n",
        "    verbose=-1,\n",
        "    n_jobs=-1,\n",
        "    lambda_l1=0.1,\n",
        "    lambda_l2=0.1\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'num_leaves': [31, 40, 50],\n",
        "    'learning_rate': [0.03, 0.05],\n",
        "    'min_child_samples': [20, 30],\n",
        "    'n_estimators': [1000]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=gbm,\n",
        "    param_grid=param_grid,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=3,\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_params = grid_search.best_params_\n",
        "print(\"\\nBest Hyperparameters from Grid Search:\")\n",
        "print(best_params)\n",
        "print(f\"Best MSE (negative): {grid_search.best_score_:.2f}\")\n",
        "\n",
        "# Step 3: Train the final model with best parameters\n",
        "final_params = {\n",
        "    'objective': 'huber',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'feature_fraction': 0.8,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'verbose': -1,\n",
        "    'n_jobs': -1,\n",
        "    'lambda_l1': 0.1,\n",
        "    'lambda_l2': 0.1,\n",
        "    **best_params\n",
        "}\n",
        "\n",
        "train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_cols, free_raw_data=False)\n",
        "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data, categorical_feature=categorical_cols, free_raw_data=False)\n",
        "\n",
        "print(\"\\nTraining Final LightGBM Model with Best Parameters...\")\n",
        "final_gbm = lgb.train(\n",
        "    final_params,\n",
        "    train_data,\n",
        "    num_boost_round=best_params['n_estimators'],\n",
        "    valid_sets=[test_data],\n",
        "    callbacks=[lgb.early_stopping(stopping_rounds=20), lgb.log_evaluation(period=10)]\n",
        ")\n",
        "\n",
        "# Step 4: Evaluate the model\n",
        "y_pred = final_gbm.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "# Calculate tolerance-based accuracy\n",
        "tolerance = 50\n",
        "absolute_errors = np.abs(y_pred - y_test)\n",
        "accuracy_within_tolerance = np.mean(absolute_errors <= tolerance) * 100\n",
        "\n",
        "print(\"\\nFinal LightGBM Performance on Test Data:\")\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "print(f\"R² Score: {r2:.2f}\")\n",
        "print(f\"Root Mean Squared Error (per trip): ${rmse:.2f}\")\n",
        "print(f\"Accuracy (within ±$50 tolerance): {accuracy_within_tolerance:.2f}%\")\n",
        "\n",
        "# Step 5: Feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': final_gbm.feature_importance(importance_type='gain')\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "print(\"\\nFinal LightGBM Feature Importance:\")\n",
        "print(feature_importance)\n",
        "\n",
        "# Step 6: Function to generate synthetic data with 2% inflation\n",
        "def generate_future_data(base_data, year, month, num_trips):\n",
        "    historical_month_data = base_data[base_data['Travel_Month'] == month].copy()\n",
        "    if historical_month_data.empty:\n",
        "        historical_month_data = base_data.copy()\n",
        "\n",
        "    future_data = historical_month_data.sample(n=num_trips, replace=True, random_state=42).copy()\n",
        "    future_data['Travel_Year'] = year\n",
        "    future_data['Travel_Month'] = month\n",
        "    future_data['Travel_Day'] = np.random.randint(1, 31, size=num_trips)\n",
        "    years_diff = year - 2018\n",
        "    future_data['Price Charged'] *= (1 + 0.02) ** years_diff  # 2% inflation\n",
        "    future_data['Cost of Trip'] *= (1 + 0.02) ** years_diff   # 2% inflation\n",
        "    future_data['Distance_Company'] = future_data['Distance Travelled(KM)'] * future_data['Company']\n",
        "    future_X = future_data.drop(columns=exclude_cols)\n",
        "    return future_X, future_data\n",
        "\n",
        "avg_trips_per_month = len(data) // (data['Travel_Year'].nunique() * 12)\n",
        "print(f\"\\nAverage Trips per Month: {avg_trips_per_month}\")\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_year = int(input(\"Enter the year for profit prediction (e.g., 2025): \"))\n",
        "        user_month = int(input(\"Enter the month for profit prediction (1-12): \"))\n",
        "        if 1 <= user_month <= 12 and user_year >= 2019:\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid input. Month must be 1-12, and year must be 2019 or later.\")\n",
        "    except ValueError:\n",
        "        print(\"Please enter valid numeric values.\")\n",
        "\n",
        "# Generate future data and predict profits\n",
        "future_X, future_data = generate_future_data(data, user_year, user_month, avg_trips_per_month)\n",
        "future_pred_profits = final_gbm.predict(future_X)\n",
        "\n",
        "# Total profit with confidence interval\n",
        "total_future_profit = future_pred_profits.sum()\n",
        "total_error = rmse * avg_trips_per_month\n",
        "print(f\"\\nPredicted Total Company Profit for {user_month}/{user_year}: ${total_future_profit:,.2f}\")\n",
        "print(f\"Estimated Range: ${total_future_profit - total_error:,.2f}–${total_future_profit + total_error:,.2f}\")\n",
        "print(f\"(Note: Range based on RMSE ±${rmse:.2f} per trip across {avg_trips_per_month} trips)\")\n",
        "\n",
        "# Breakdown by company\n",
        "future_data['Predicted_Profit'] = future_pred_profits\n",
        "future_data['Company'] = label_encoders['Company'].inverse_transform(future_data['Company'])\n",
        "profit_by_company = future_data.groupby('Company')['Predicted_Profit'].sum()\n",
        "pink_cab_profit = profit_by_company.get('Pink Cab', 0)\n",
        "yellow_cab_profit = profit_by_company.get('Yellow Cab', 0)\n",
        "pink_error = total_error * (pink_cab_profit / total_future_profit) if total_future_profit != 0 else 0\n",
        "yellow_error = total_error * (yellow_cab_profit / total_future_profit) if total_future_profit != 0 else 0\n",
        "\n",
        "print(f\"\\nProfit Breakdown by Company for {user_month}/{user_year}:\")\n",
        "print(f\"Pink Cab: ${pink_cab_profit:,.2f} (Range: ${pink_cab_profit - pink_error:,.2f}–${pink_cab_profit + pink_error:,.2f})\")\n",
        "print(f\"Yellow Cab: ${yellow_cab_profit:,.2f} (Range: ${yellow_cab_profit - yellow_error:,.2f}–${yellow_cab_profit + yellow_error:,.2f})\")\n",
        "print(f\"Total (Pink Cab + Yellow Cab): ${(pink_cab_profit + yellow_cab_profit):,.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7zbQWefxSWh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}